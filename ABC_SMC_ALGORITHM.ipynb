{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8qk1XKFokP6C5Gk7+qE2j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vgarcialopezm/ABC-SMC/blob/main/ABC_SMC_ALGORITHM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABC SMC "
      ],
      "metadata": {
        "id": "-IP3ADEIlHW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains all the necessary functions to include in the ABC SMC algorithm. "
      ],
      "metadata": {
        "id": "ufFWXRe2lPX9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wQYfYPXEmisk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm, uniform, multivariate_normal\n",
        "from scipy.optimize import minimize\n",
        "from scipy.special import logsumexp\n",
        "import sys,ast\n",
        "from math import exp\n",
        "from math import log\n",
        "from random import choices,seed,random\n",
        "from tqdm import tqdm\n",
        "#import p_tqdm\n",
        "from functools import partial\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import exp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function *euc_dist* calculates the SSE (sum of squared errors) betweeen two data sets. The distance between them is compared to the tolerance fixed to decide if the sample is accepted or not."
      ],
      "metadata": {
        "id": "CyhTxKFclee2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euc_dist(data1, data2):\n",
        "    if np.shape(data1) != np.shape(data2):\n",
        "        print (\"\\n the dimensions of the datasets are different (%s v.s. %s)\\n\" % (len(data1), len(data2)))\n",
        "        sys.exit()\n",
        "    else:\n",
        "        z=np.array((data1 - data2)**2)\n",
        "        distance = np.sum(z)\n",
        "        #print('dist',data1 - data2)\n",
        "\n",
        "    if distance < 0:\n",
        "        return [None]\n",
        "    elif np.isnan(distance):\n",
        "        distance=100000\n",
        "        return distance\n",
        "    else:\n",
        "        return distance\n"
      ],
      "metadata": {
        "id": "LXlqZHZrm-Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function *prior* generates a random parameter inside the limits stablished for each of them according to a Uniform distribution. It is used at first step of ABC SMC (time t=0)."
      ],
      "metadata": {
        "id": "ufhJWjvMmYum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prior():\n",
        "### Generate a random parameter inside the limits stablished. The shape of the distribution can be changed if required\n",
        "    prior = []\n",
        "    for ipar,par in enumerate(params_tumor):\n",
        "        prior.append(uniform.rvs(loc = par['lower_limit'],\n",
        "                                 scale = par['upper_limit']-par['lower_limit'])) #par['upper_limit']))\n",
        "        \n",
        "       \n",
        "    return prior\n"
      ],
      "metadata": {
        "id": "Pt5fn1AVm_ka"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*evaluate_prev_pru* : function that given the values of the parameters of a particle, obtains the joint probability density function."
      ],
      "metadata": {
        "id": "vovFvE9Ym0L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate_prev_pru(params):\n",
        "    print('parameters',params)\n",
        "    l=len(params)\n",
        "    prior = 1\n",
        "    for ipar,par in enumerate(params_tumor):\n",
        "    #for i in range(l):\n",
        "        prior *= uniform.pdf(params[ipar],loc = par['lower_limit'],\n",
        "                                 scale = par['upper_limit']-par['lower_limit'])\n",
        "        if prior==0:\n",
        "            break   \n",
        "      #  print('params i', params[i])\n",
        "       # print('prior',prior)\n",
        "    return prior\n"
      ],
      "metadata": {
        "id": "8elCdwRBnKRf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*perturb*: function that, given a list of parameters sampled (a particle), perturbs it by applying a multivariate normal kernel"
      ],
      "metadata": {
        "id": "lBa1j06FnxnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function that, given a list of parameters sampled, perturbs it by applying a multivariate normal kernel\n",
        "def perturb(listaprev,s):\n",
        "    #print(listaprev)\n",
        "    lista=np.asarray(listaprev) #.tolist()\n",
        "    #mean_vec=np.mean(lista)\n",
        "    cov_matrix=2.0*np.cov(lista.T)  #the covariance matrix for the multivariate normal perturbation kernel is given by this expression\n",
        "    kernel=multivariate_normal(cov=cov_matrix)\n",
        "    pert=s+kernel.rvs() # here we obtain the list of perturbed parameters\n",
        "    pertur=pert.tolist()\n",
        "    return pertur\n"
      ],
      "metadata": {
        "id": "qZNTagy8nMcN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*weighting*: function that gives the denominator used to calculate the weights of every particle"
      ],
      "metadata": {
        "id": "mi1yhQMNoBRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function that gives the denominator used to calculate the weights of every particle.\n",
        "def weighting(i,j,N,sam,wei,sampre):\n",
        "     denom=0\n",
        "     #ker=1\n",
        "     samprev=np.asarray(sampre)\n",
        "     cov_matrix=2.0*np.cov(samprev.T)\n",
        "     kernel=multivariate_normal(cov=cov_matrix)\n",
        "     for k in range(N):\n",
        "            sampre[k]=np.array(sampre[k])\n",
        "            \n",
        "            ker=kernel.pdf(sam[j]-sampre[k])\n",
        "            #print('ker',ker)\n",
        "            #kerne=np.prod(ker)  #here we are obtaining the joint probability of the parameter vector obtained when applying the kernel\n",
        "            denom+=wei[k]*ker #kerne\n",
        "     #print('den',denom)      \n",
        "     return denom\n"
      ],
      "metadata": {
        "id": "_DSo-9uinQbH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function used to normalize the weights\n",
        "def normalize(wei):\n",
        "    #normalized=wei/np.linalg.norm(wei)\n",
        "    normalized=wei/np.sum(wei)\n",
        "    return normalized  \n",
        "\n"
      ],
      "metadata": {
        "id": "mKmBVJzvnnYt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABC-SMC algorithm"
      ],
      "metadata": {
        "id": "_pEdtM6KoOUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The principal function uses all the previous functions in order to generate the ABC SMC algorithm as it has been stablished in the project. The goal is to obtain a sampled list of parameters that gives the best approximation to the target data. "
      ],
      "metadata": {
        "id": "emU-Imi7oZGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def principal(epsilons,listaparametros,N,data1,t):\n",
        "    T=len(epsilons)\n",
        "    weight=np.zeros((T,N),float)\n",
        "    dist=np.zeros((T,N),float)\n",
        "    sample=np.zeros((T,N),list)\n",
        "    X0=[1.0,0.5]\n",
        "    #t=np.linspace(0.,10,10)\n",
        "    for i in range(T):\n",
        "        count=0\n",
        "        counti=0\n",
        "        label=i\n",
        "        print(\"SMC step with target distance: {}\".format(epsilons[i]))\n",
        "        if i==0:  #first time step. The particle is sampled from the prior distribution.\n",
        "            for j in range (N):\n",
        "                dist[i,j]=epsilons[i]+1\n",
        "                while dist[i,j]>epsilons[i]:\n",
        "                    sample[i,j]=prior()\n",
        "                    #sample[i,j]=np.array(prior())\n",
        "                    sample[i,j]=np.asarray(sample[i,j])\n",
        "                    data2= rk4(lotka_volterra,X0,t,sample[i,j]) #this function changes depending on the model to solve as well as the number of parameters\n",
        "                    #print('data2',data2)\n",
        "                    #data2=np.array(data2, dtype=np.float64)\n",
        "                    dist[i,j]=euc_disti(data1,data2)  #distance between target data and the new data obtained to decide if accepting or not the particle.\n",
        "                    #print('distcondata2',dist[i,j])\n",
        "                count+=1\n",
        "                print(count)\n",
        "       \n",
        "        else:  #procedure followed after the first time step. The particles are sampled from the previous one\n",
        "        \n",
        "            for j in range (N):\n",
        "                dist[i,j]=epsilons[i]+1\n",
        "                while dist[i,j]>epsilons[i]:\n",
        "                    seed()\n",
        "                    np.random.seed()\n",
        "                    choose = choices(sample[i-1,:], weights = weight[i-1,:],k=1)[0] # select a point from the previous sample\n",
        "                    sample[i,j]=choose\n",
        "                    #print(\"before perturb\",type(sample[i,j]))\n",
        "                    #print(\"before perturb\",list(sample[i-1,:]))\n",
        "                    sample[i,j] = perturb(list(sample[i-1,:]),sample[i,j]) # and perturb it\n",
        "                    #print(\"after perturb\", sample[i,j])\n",
        "                    #print(\"after perturb\", type(sample[i,j]))\n",
        "                    evaluation=evaluate_prev_pru(sample[i,j]) \n",
        "                    if evaluation>0:\n",
        "                        data2=rk4(lotka_volterra,X0,t,sample[i,j]) #solve the model with the parameters inferred\n",
        "                        data2=np.array(data2)\n",
        "                        #print('data2',data2)\n",
        "                        dist[i,j]=euc_disti(data1,data2) #calculate distance to target data\n",
        "                        print('distendata2',dist[i,j])\n",
        "                counti+=1\n",
        "                print(counti)\n",
        "        for j in range(N):\n",
        "            if i==0:\n",
        "                weight[i,j]=1\n",
        "               # print(weight[i,j])\n",
        "            else:\n",
        "                denom=weighting(i,j,N,sample[i,:],weight[i-1,:],list(sample[i-1,:]))\n",
        "                weight[i,j]=evaluate_prev_pru(sample[i,j])/denom\n",
        "        #print('weight[i,:]',weight[i,:])\n",
        "        if i!=0:\n",
        "           weight[i,:]=normalize(weight[i,:])\n",
        "    return sample, weight, dist,data2"
      ],
      "metadata": {
        "id": "9Eru1lcUorpu"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}